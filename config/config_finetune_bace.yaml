task_name: bace    # 分类：bace, bbbp, clintox, tox21, toxcast, sider
                   # 回归：freesolv, esol, lipophilicity

batch_size: 16
seed: 12
epochs: 200
patience: 15

root: /mnt/8t/qjb/workspace/SCAGE_DATA/finetune_data/
is_pretrain: False
split_type: random_scaffold            # random, scaffold, random_scaffold
save_ckpt: 50
save_model: best_valid
pretrain_model_path: ./pretrain_model/10.10_trick/
checkpoint: False
DP: False

optim:
  type: adam
  init_lr: 0.0002                # initial learning rate for the prediction head
  init_base_lr: 0.0001           # initial learning rate for the base GNN encoder
  weight_decay: 2e-5             # weight decay of Adam

lr_scheduler:
  type: None
  warm_up_epoch: 10
  start_lr: 0.00001

model:
  use_sms: True
  # transformer layer
  num_encoder_layers: 3
  hidden_dim: 128
  ffn_hidden_dim: 128
  num_attn_heads: 4
  emb_dropout: 0.1
  dropout: 0.1
  attn_dropout: 0.1
  dist_bar: [1, 2, 3]
  encoder_normalize_before: True
  apply_graphormer_init: True
  activation_fn: GELU
  n_trans_layers_to_freeze: 0

  use_super_node: True
  graph_pooling: afps      # mean, afps
  afps_k: 10

  # 是否使用额外特征
  node_level_modules:
    - degree
  attn_level_modules:
    - geometry
  attn_mask_modules: None

  # PE
  num_in_degree: 512
  num_out_degree: 512
  eig_pos_dim: 3
  svd_pos_dim: 3

  # AT
  num_spatial: 512  # 最短路径的数目
  num_edges: 1536  # 512*3
  num_edge_dis: 128
  edge_type: multi_hop
  multi_hop_max_dist: 5
  num_hop_bias: 3   # 2/3/4

  # GNN
  use_gnn_layers: True
  gnn_insert_pos: before
  num_gnn_layers: 2
  residual: True
  JK: last
  gnn_type: gin
  gnn_dropout: 0.1

  # collator
  max_node: 512
  spatial_pos_max: 20

DownstreamModel:
  inp_dim: 128
  hidden_dim: 128
  num_layers: 2
  batch_norm: True
  dropout: 0.5
